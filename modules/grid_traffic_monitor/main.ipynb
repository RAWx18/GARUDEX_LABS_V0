{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from grid_traffic_monitor import GridTrafficMonitor\n",
    "from traffic_congestion_pred import TrafficCongestionPredictor\n",
    "import time\n",
    "from datetime import datetime\n",
    "import h3\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prepare_features(traffic_df: pd.DataFrame, num_nodes: int, num_timesteps: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Prepare features in the correct shape for the predictor.\n",
    "    \n",
    "    Args:\n",
    "        traffic_df: DataFrame containing traffic data\n",
    "        num_nodes: Number of nodes (hexagons) in the grid\n",
    "        num_timesteps: Number of timesteps for prediction\n",
    "    \n",
    "    Returns:\n",
    "        Properly shaped feature array\n",
    "    \"\"\"\n",
    "    print(f\"\\nPreparing features:\")\n",
    "    print(f\"Input DataFrame shape: {traffic_df.shape}\")\n",
    "    print(f\"Number of nodes: {num_nodes}\")\n",
    "    print(f\"Number of timesteps: {num_timesteps}\")\n",
    "\n",
    "    # Ensure the necessary columns exist\n",
    "    required_columns = ['traffic_density', 'time_of_day', 'day_of_week']\n",
    "    if not all(col in traffic_df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing one or more required columns: {required_columns}\")\n",
    "\n",
    "    # Get unique timestamps and sort them\n",
    "    timestamps = traffic_df['time_of_day'].unique()\n",
    "    timestamps.sort()\n",
    "    \n",
    "    # Take the most recent num_timesteps timestamps\n",
    "    recent_timestamps = timestamps[-num_timesteps:] if len(timestamps) >= num_timesteps else timestamps\n",
    "\n",
    "    # Initialize feature array\n",
    "    features = np.zeros((1, num_timesteps, num_nodes, len(required_columns)))\n",
    "\n",
    "    # Fill in the features array with available data\n",
    "    for t, timestamp in enumerate(recent_timestamps):\n",
    "        time_data = traffic_df[traffic_df['time_of_day'] == timestamp]\n",
    "        \n",
    "        for n, hex_id in enumerate(traffic_df['hex_id'].unique()):\n",
    "            hex_data = time_data[time_data['hex_id'] == hex_id]\n",
    "            if not hex_data.empty:\n",
    "                features[0, t, n, :] = hex_data[required_columns].iloc[0].values\n",
    "\n",
    "    print(f\"Output feature array shape: {features.shape}\")\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Initialize GridTrafficMonitor with more conservative parameters\n",
    "    monitor = GridTrafficMonitor(\n",
    "        base_resolution=8,\n",
    "        min_resolution=7,\n",
    "        max_resolution=10,\n",
    "        min_traffic_density=100.0,\n",
    "        max_merge_threshold=20.0,\n",
    "        smoothing_factor=0.3\n",
    "    )\n",
    "\n",
    "    # Load city boundary\n",
    "    try:\n",
    "        print(\"Loading geographic data...\")\n",
    "        city_gdf = monitor.load_city_boundary('/home/raw/Desktop/Coding/Jhakaas_Rasta/geopkg/Ahmedabad.gpkg')\n",
    "        boundary_gdf = gpd.read_file('/home/raw/Desktop/Coding/Jhakaas_Rasta/geopkg/clipping_boundary.geojson')\n",
    "        \n",
    "        if city_gdf.crs != boundary_gdf.crs:\n",
    "            boundary_gdf = boundary_gdf.to_crs(city_gdf.crs)\n",
    "        \n",
    "        city_gdf = gpd.clip(city_gdf, boundary_gdf)\n",
    "        print(\"Geographic data loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading geographic data: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Initialize grid system\n",
    "    try:\n",
    "        print(\"Initializing grid system...\")\n",
    "        hex_polygons = monitor.initialize_grid(city_gdf)\n",
    "        num_nodes = len(hex_polygons)\n",
    "        print(f\"Grid system initialized with {num_nodes} hexagons\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing grid system: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Initialize traffic predictor with correct number of nodes\n",
    "    try:\n",
    "        print(\"Initializing traffic predictor...\")\n",
    "        predictor = TrafficCongestionPredictor(\n",
    "            num_nodes=num_nodes,  # Using the actual number of hexagons\n",
    "            input_dim=3,  # traffic_density, time_of_day, day_of_week\n",
    "            hidden_dims=[64, 32, 16],\n",
    "            output_dim=1,\n",
    "            num_timesteps=12,\n",
    "            batch_size=32\n",
    "        )\n",
    "        print(\"Traffic predictor initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing traffic predictor: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Initialize historical data storage\n",
    "    historical_data = []\n",
    "\n",
    "    # Simulate real-time updates\n",
    "    try:\n",
    "        while True:\n",
    "            current_time = datetime.now()\n",
    "            \n",
    "            # Simulate traffic updates\n",
    "            traffic_data = []\n",
    "            hex_ids = list(monitor.current_grids.keys())\n",
    "            \n",
    "            print(f\"Number of hexagons being processed: {len(hex_ids)}\")\n",
    "            \n",
    "            for hex_id in hex_ids:\n",
    "                hour = current_time.hour\n",
    "                base_density = 50 + 50 * np.sin(np.pi * hour / 12)\n",
    "                noise = np.random.normal(0, 10)\n",
    "                new_density = max(0, base_density + noise)\n",
    "\n",
    "                monitor.update_traffic_density(hex_id, new_density)\n",
    "\n",
    "                traffic_data.append({\n",
    "                    'hex_id': hex_id,\n",
    "                    'traffic_density': new_density,\n",
    "                    'time_of_day': current_time.hour + current_time.minute / 60,\n",
    "                    'day_of_week': current_time.weekday()\n",
    "                })\n",
    "\n",
    "            # Create DataFrame and store in historical data\n",
    "            current_df = pd.DataFrame(traffic_data)\n",
    "            print(\"\\nTraffic DataFrame preview:\")\n",
    "            print(current_df.head())\n",
    "            print(f\"Total records in current update: {len(current_df)}\")\n",
    "\n",
    "            historical_data.append(current_df)\n",
    "\n",
    "            # Keep only recent history\n",
    "            if len(historical_data) > predictor.num_timesteps:\n",
    "                historical_data.pop(0)\n",
    "\n",
    "            # Combine historical data\n",
    "            traffic_df = pd.concat(historical_data, ignore_index=True)\n",
    "            print(f\"\\nCombined historical data shape: {traffic_df.shape}\")\n",
    "\n",
    "            # Create visualization first (so we always have it)\n",
    "            center_lat = city_gdf.geometry.centroid.y.iloc[0]\n",
    "            center_lon = city_gdf.geometry.centroid.x.iloc[0]\n",
    "            m = monitor.visualize_grid(center_lat, center_lon)\n",
    "\n",
    "            # Try predictions\n",
    "            try:\n",
    "                features, targets, adj_matrix = predictor.prepare_data(\n",
    "                    traffic_df,\n",
    "                    hex_ids\n",
    "                )\n",
    "                \n",
    "                shaped_features = prepare_features(\n",
    "                    traffic_df, \n",
    "                    num_nodes,\n",
    "                    predictor.num_timesteps\n",
    "                )\n",
    "\n",
    "                predictions = predictor.predict(shaped_features, adj_matrix)\n",
    "\n",
    "                # Display predictions\n",
    "                print(\"\\nPredicted traffic densities (next timestep):\")\n",
    "                for hex_id, pred in zip(hex_ids, predictions[0]):\n",
    "                    print(f\"{hex_id}: {pred[0]:.2f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in prediction step: {str(e)}\")\n",
    "                print(\"Continuing monitoring without predictions...\")\n",
    "\n",
    "            # Display statistics\n",
    "            stats = monitor.get_grid_stats()\n",
    "            print(\"\\nGrid Statistics:\")\n",
    "            for key, value in stats.items():\n",
    "                print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "            # Display visualization (guaranteed to exist now)\n",
    "            display(m)\n",
    "\n",
    "            # Wait before next update\n",
    "            time.sleep(300)  # 5 minutes\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nMonitoring stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during monitoring: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "840b4ea9aeeb183f4de2f05363849475686b0eeb72643ce816304187d8219f68"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
